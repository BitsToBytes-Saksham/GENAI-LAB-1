# GENAI-LAB-1
# Unit 1 – Generative 

## Student Details
- Name: Saksham Gupta
- SRN: PES2UG23CS513
- Section: H
- Course: Generative AI and Its Applications

---

## Assignment 1: Model Benchmark Challenge

This notebook compares three transformer architectures:
- BERT (Encoder-only)
- RoBERTa (Encoder-only)
- BART (Encoder–Decoder)

Each model is tested on:
- Text Generation
- Fill-Mask
- Question Answering

The experiments highlight how architecture and training objectives impact performance.

---

## Assignment 2: Mini Project – TL;DR Summarizer

This mini-project implements a TL;DR text summarizer using a transformer-based summarization pipeline (`distilbart-cnn-12-6`).  
The model successfully generates concise summaries from long text inputs.

---

## Key Concepts Learned
- Transformer architectures
- Hugging Face pipelines
- Model-task compatibility
- Importance of fine-tuning

