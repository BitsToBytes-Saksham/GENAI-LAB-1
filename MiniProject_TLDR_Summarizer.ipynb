{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TL;DR Text Summarizer using Hugging Face**\n",
        "## Objective\n",
        "\n",
        "This project builds a TL;DR text summarizer that automatically condenses long paragraphs into a short, meaningful summary using a transformer-based abstractive summarization model from Hugging Face.\n",
        "\n",
        "The goal is to demonstrate how encoder–decoder transformer models can generate concise summaries from unstructured text without additional training."
      ],
      "metadata": {
        "id": "RJdtOtDHITY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and Imports"
      ],
      "metadata": {
        "id": "aHoAFNNYVg9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch --quiet\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621uUDsYIj5R",
        "outputId": "c088b197-f5fa-4e13-c71f-89cf334c423d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Technique Used\n",
        "\n",
        "Task: Text Summarization\n",
        "\n",
        "Pipeline: pipeline(\"summarization\")\n",
        "\n",
        "Model: sshleifer/distilbart-cnn-12-6\n",
        "\n",
        "Architecture: Encoder–Decoder (BART-based)\n",
        "\n",
        "This model is fine-tuned on the CNN/DailyMail dataset and is optimized for fast and accurate abstractive summarization."
      ],
      "metadata": {
        "id": "fe2xj_SXVp2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Summarization Pipeline"
      ],
      "metadata": {
        "id": "jHmMFIC5VyRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"sshleifer/distilbart-cnn-12-6\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kFkjrd2I3l8",
        "outputId": "2461011b-51c6-44fc-ec37-eafbbde716b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Text"
      ],
      "metadata": {
        "id": "_uIkITUvV2Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Generative Artificial Intelligence refers to a class of AI systems capable of creating new content such as text, images, audio, and video.\n",
        "These systems are powered by large language models trained on massive datasets using deep learning techniques.\n",
        "The introduction of transformer-based architectures has significantly improved the ability of models to understand context and generate coherent outputs.\n",
        "Despite their impressive capabilities, generative AI systems also pose serious risks including hallucinations, bias, misinformation, and ethical concerns.\n",
        "As these models become more widely adopted, it is essential to develop responsible AI practices and ensure transparency and accountability in their use.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CkggaadQKR4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Summary"
      ],
      "metadata": {
        "id": "MGZ65Ft-V5rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarizer(\n",
        "    text,\n",
        "    max_length=60,\n",
        "    min_length=25,\n",
        "    do_sample=False\n",
        ")\n",
        "\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AymZSIfeKVM4",
        "outputId": "d581318f-3d2d-4c0f-a349-79c16368196b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Generative Artificial Intelligence refers to a class of AI systems capable of creating new content such as text, images, audio, and video . Generative AI systems are powered by large language models trained on massive datasets .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Output Clearly"
      ],
      "metadata": {
        "id": "lXZVlzedV_Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ORIGINAL TEXT:\\n\")\n",
        "print(text)\n",
        "\n",
        "print(\"\\nSUMMARY:\\n\")\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlIHYuoeKaYp",
        "outputId": "0f6fefce-1d29-42ba-d877-6cd569897bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TEXT:\n",
            "\n",
            "\n",
            "Generative Artificial Intelligence refers to a class of AI systems capable of creating new content such as text, images, audio, and video. \n",
            "These systems are powered by large language models trained on massive datasets using deep learning techniques. \n",
            "The introduction of transformer-based architectures has significantly improved the ability of models to understand context and generate coherent outputs. \n",
            "Despite their impressive capabilities, generative AI systems also pose serious risks including hallucinations, bias, misinformation, and ethical concerns. \n",
            "As these models become more widely adopted, it is essential to develop responsible AI practices and ensure transparency and accountability in their use.\n",
            "\n",
            "\n",
            "SUMMARY:\n",
            "\n",
            " Generative Artificial Intelligence refers to a class of AI systems capable of creating new content such as text, images, audio, and video . Generative AI systems are powered by large language models trained on massive datasets .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation\n",
        "\n",
        "This project uses a transformer-based encoder–decoder model to perform abstractive text summarization.\n",
        "The encoder processes the input text and captures its contextual meaning, while the decoder generates a shorter version that preserves the core ideas.\n",
        "\n",
        "The selected model (distilbart-cnn-12-6) is a distilled version of BART, making it efficient while still producing high-quality summaries. This demonstrates how pre-trained summarization models can be directly applied to real-world productivity tasks such as document summarization, news summarization, and report condensation."
      ],
      "metadata": {
        "id": "Eue3gvTCVO9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations\n",
        "\n",
        "- The summarization model successfully condensed a long paragraph into a short and meaningful summary.\n",
        "- The generated summary preserved the key ideas while removing unnecessary details.\n",
        "- The model used is an encoder-decoder transformer fine-tuned specifically for abstractive summarization.\n",
        "- This demonstrates how pre-trained Hugging Face pipelines can be used to solve real-world NLP tasks efficiently.\n"
      ],
      "metadata": {
        "id": "fThHicI6KfLJ"
      }
    }
  ]
}